{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41977d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64661ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) load key from .env\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    print(\"⚠️  Missing OPENAI_API_KEY in .env\", file=sys.stderr)\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f69fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models you can use:\n",
      "  - gpt-4-0613\n",
      "  - gpt-4\n",
      "  - gpt-3.5-turbo\n",
      "  - gpt-4o-audio-preview-2025-06-03\n",
      "  - gpt-4.1-nano-2025-04-14\n",
      "  - gpt-4.1-nano\n",
      "  - gpt-image-1\n",
      "  - gpt-4o-realtime-preview-2025-06-03\n",
      "  - davinci-002\n",
      "  - babbage-002\n",
      "  - gpt-3.5-turbo-instruct\n",
      "  - gpt-3.5-turbo-instruct-0914\n",
      "  - dall-e-3\n",
      "  - dall-e-2\n",
      "  - gpt-4-1106-preview\n",
      "  - gpt-3.5-turbo-1106\n",
      "  - tts-1-hd\n",
      "  - tts-1-1106\n",
      "  - tts-1-hd-1106\n",
      "  - text-embedding-3-small\n",
      "  - text-embedding-3-large\n",
      "  - gpt-4-0125-preview\n",
      "  - gpt-4-turbo-preview\n",
      "  - gpt-3.5-turbo-0125\n",
      "  - gpt-4-turbo\n",
      "  - gpt-4-turbo-2024-04-09\n",
      "  - gpt-4o\n",
      "  - gpt-4o-2024-05-13\n",
      "  - gpt-4o-mini-2024-07-18\n",
      "  - gpt-4o-mini\n",
      "  - gpt-4o-2024-08-06\n",
      "  - chatgpt-4o-latest\n",
      "  - o1-preview-2024-09-12\n",
      "  - o1-preview\n",
      "  - o1-mini-2024-09-12\n",
      "  - o1-mini\n",
      "  - gpt-4o-realtime-preview-2024-10-01\n",
      "  - gpt-4o-audio-preview-2024-10-01\n",
      "  - gpt-4o-audio-preview\n",
      "  - gpt-4o-realtime-preview\n",
      "  - omni-moderation-latest\n",
      "  - omni-moderation-2024-09-26\n",
      "  - gpt-4o-realtime-preview-2024-12-17\n",
      "  - gpt-4o-audio-preview-2024-12-17\n",
      "  - gpt-4o-mini-realtime-preview-2024-12-17\n",
      "  - gpt-4o-mini-audio-preview-2024-12-17\n",
      "  - o1-2024-12-17\n",
      "  - o1\n",
      "  - gpt-4o-mini-realtime-preview\n",
      "  - gpt-4o-mini-audio-preview\n",
      "  - o3-mini\n",
      "  - o3-mini-2025-01-31\n",
      "  - gpt-4o-2024-11-20\n",
      "  - gpt-4.5-preview\n",
      "  - gpt-4.5-preview-2025-02-27\n",
      "  - gpt-4o-search-preview-2025-03-11\n",
      "  - gpt-4o-search-preview\n",
      "  - gpt-4o-mini-search-preview-2025-03-11\n",
      "  - gpt-4o-mini-search-preview\n",
      "  - gpt-4o-transcribe\n",
      "  - gpt-4o-mini-transcribe\n",
      "  - o1-pro-2025-03-19\n",
      "  - o1-pro\n",
      "  - gpt-4o-mini-tts\n",
      "  - gpt-4.1-2025-04-14\n",
      "  - gpt-4.1\n",
      "  - gpt-4.1-mini-2025-04-14\n",
      "  - gpt-4.1-mini\n",
      "  - gpt-3.5-turbo-16k\n",
      "  - tts-1\n",
      "  - whisper-1\n",
      "  - text-embedding-ada-002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) list available models\n",
    "print(\"Models you can use:\")\n",
    "for m in openai.models.list().data:\n",
    "    print(\"  -\", m.id)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f8bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Simple ChatCompletion\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Give me three bullet points on why AI is exciting.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b61bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response:\n",
      "1. AI has the potential to revolutionize various industries by increasing efficiency and productivity through automation and advanced data analysis.\n",
      "2. AI technology is constantly evolving and improving, leading to exciting breakthroughs in areas such as self-driving cars, natural language processing, and medical diagnostics.\n",
      "3. AI has the ability to tackle complex problems and make predictions that were previously impossible with traditional methods, opening up new possibilities for innovation and discovery.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Chat response:\")\n",
    "print(response.choices[0].message.content.strip())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d80604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      "In lines of code flow  \n",
      "Logic and creativity  \n",
      "Programmers create\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Streaming response example (updated)\n",
    "print(\"Streaming response:\")\n",
    "stream = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that streams your reply.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Stream me a haiku about coding.\"}\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    stream=True,\n",
    ")\n",
    "# Each `chunk` is a ChatCompletionChunk; delta.content holds the new text (or None)\n",
    "for chunk in stream:\n",
    "    delta_text = chunk.choices[0].delta.content\n",
    "    if delta_text:\n",
    "        print(delta_text, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "847d94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Function-calling stub\n",
    "def get_current_weather(location: str) -> dict:\n",
    "    # Dummy implementation — replace with real API calls if desired\n",
    "    return {\"location\": location, \"weather\": \"sunny\", \"temperature\": \"25°C\"}\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",  # or simply \"gpt-3.5-turbo\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a weather bot.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"What's the weather in Paris today?\"}\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    "    max_tokens=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb00cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call result: {'location': 'Paris', 'weather': 'sunny', 'temperature': '25°C'}\n"
     ]
    }
   ],
   "source": [
    "# new Pydantic message object; function_call is an attribute \n",
    "message = response.choices[0].message\n",
    "if message.function_call:  # :contentReference[oaicite:2]{index=2}\n",
    "    args = json.loads(message.function_call.arguments)\n",
    "    weather = get_current_weather(**args)\n",
    "    print(\"Function call result:\", weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d332f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
